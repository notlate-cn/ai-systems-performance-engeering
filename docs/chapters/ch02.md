# 第2章 AI系统硬件概述

想象一下将超级计算机级别的AI硬件浓缩到单个机柜中。NVIDIA的最新架构正是做到了这一点。在本章中，我们将深入探讨NVIDIA如何将CPU和GPU融合为强大的超级芯片，然后通过超高速互连将数十个这样的芯片连接起来，创建一个"盒中AI超级计算机"。我们将探索基本的硬件构建模块——Grace CPU和Blackwell GPU——并了解它们的紧密集成和巨大的内存池如何让AI工程师的工作变得更加轻松。

> Imagine condensing a supercomputer's worth of AI hardware into a single rack. NVIDIA's latest architecture does exactly that. In this chapter, we dive into how NVIDIA fused CPUs and GPUs into powerful superchips and then wired dozens of them together with ultrafast interconnects to create an AI supercomputer-in-a-box. We'll explore the fundamental hardware building blocks—the Grace CPU and Blackwell GPU—and see how their tight integration and enormous memory pool make life easier for AI engineers.

然后，我们将扩展到连接72个GPU的网络架构，使它们就像一台机器一样工作。在此过程中，我们将重点介绍计算性能、内存容量和效率方面的飞跃，这些赋予了这个系统超能力。到最后，你将理解这一尖端硬件如何实现训练和服务以前看似不可能的多万亿参数模型。

> Then we'll expand outward to the networking fabric that links 72 of these GPUs as if they were one machine. Along the way, we'll highlight the leaps in compute performance, memory capacity, and efficiency that give this system its superpowers. By the end, you'll appreciate how this cutting-edge hardware enables training and serving multi-trillion-parameter models that previously seemed impossible.

## 2.1 CPU和GPU超级芯片

NVIDIA扩展AI的方法始于单个组合的CPU + GPU超级芯片模块级别。从Hopper代开始，NVIDIA开始将基于ARM的CPU与一个或多个GPU封装在同一单元中，通过高速接口紧密连接它们。结果是一个行为像统一计算引擎的单一模块。

> NVIDIA's approach to scaling AI starts at the level of a single, combined CPU + GPU superchip module. Beginning with the Hopper generation, NVIDIA started packaging an ARM-based CPU together with one or more GPUs in the same unit, tightly linking them with a high-speed interface. The result is a single module that behaves like a unified computing engine.

超级芯片的第一个实现是Grace Hopper（GH200），它将一个Grace CPU与一个Hopper GPU配对。接下来是Grace Blackwell（GB200）超级芯片，它将一个Grace CPU与两个Blackwell GPU封装在同一封装中。Grace CPU位于模块中心，两侧是两个Blackwell GPU裸片，如图2-1所示。

> The first implementation of the superchip was Grace Hopper (GH200), which pairs one Grace CPU with one Hopper GPU. Next came the Grace Blackwell (GB200) Superchip, which pairs one Grace CPU with two Blackwell GPUs in the same package. The Grace CPU sits in the center of the module, surrounded by two Blackwell GPU dies, as shown in Figure 2-1.

![图2-1 NVIDIA Grace Blackwell超级芯片模块](../assets/images/ch02/fig2_47_1.png)

在传统系统中，CPU和GPU有独立的内存池，通过相对较慢的总线（如PCIe）进行通信，这意味着数据必须来回复制。NVIDIA的超级芯片通过使用称为NVLink-C2C（芯片到芯片）的定制高速链路连接CPU和GPU，消除了这一障碍。

> In a traditional system, the CPU and GPU have separate memory pools and communicate over a relatively slow bus (like PCIe), which means data has to be copied back and forth. NVIDIA's superchip eliminates that barrier by connecting the CPU and GPUs with a custom high-speed link called NVLink-C2C (chip-to-chip).

NVLink-C2C在GB200超级芯片中提供Grace CPU和Blackwell GPU之间高达约900 GB/s的带宽。相比之下，PCIe Gen5 x16（Blackwell B200）每个方向约64 GB/s，PCIe Gen6 x16（Blackwell Ultra B300）每个方向约128 GB/s。NVLink-C2C的互连速度比典型PCIe快一个数量级。而且，重要的是，它是缓存一致的。

> NVLink-C2C provides up to ~900 GB/s between the Grace CPU and the Blackwell GPUs in GB200 Superchips. By comparison, PCIe Gen5 x16 (Blackwell B200) is about 64 GB/s per direction, and PCIe Gen6 x16 (Blackwell Ultra B300) is about 128 GB/s per direction. NVLink-C2C's interconnect speed is an order of magnitude faster than typical PCIe. And, importantly, it is cache-coherent.

缓存一致性意味着CPU和GPU共享一致的统一内存架构。因此，它们始终看到相同的值。在实践中，超级芯片上的Grace CPU和Blackwell GPU都可以直接访问彼此的内存，就像它是一个巨大的内存池一样。GPU可以读取或写入存储在CPU内存中的数据，反之亦然，无需显式复制。这种统一内存架构通常被NVIDIA称为统一CPU-GPU内存或扩展GPU内存（EGM），它有效地模糊了CPU内存和GPU内存之间的界限。

> Cache coherency means the CPU and GPU share a coherent, unified memory architecture. As such, they always see the same values. In practice, the Grace CPU and Blackwell GPUs on a superchip can all access one another's memory directly as if it were one huge memory pool. The GPU can read or write data stored in the CPU's memory, and vice versa, without needing explicit copies. This unified memory architecture is often called Unified CPU-GPU Memory or Extended GPU Memory (EGM) by NVIDIA, and it effectively blurs the line between CPU memory and GPU memory.

每个Grace Blackwell超级芯片承载着巨大的内存量。Grace CPU附带数百GB的LPDDR5X DRAM，每个Blackwell GPU都有自己的高速高带宽内存（HBM）堆栈。

> Each Grace Blackwell Superchip carries a tremendous amount of memory. The Grace CPU comes with hundreds of gigabytes of LPDDR5X DRAM attached, and each Blackwell GPU has its own high-speed, high-bandwidth memory (HBM) stacks.

在GB200超级芯片中，Grace CPU提供高达约480 GB的LPDDR5X，带宽高达约500 GB/s，两个Blackwell GPU共同贡献高达约384 GB的HBM3e内存（每个GPU总共192 GB）。总的来说，GB200超级芯片在统一地址空间中暴露了约900 GB的可被GPU和CPU访问的一致统一内存。

> In the GB200 Superchip, the Grace CPU provides up to ~480 GB of LPDDR5X at up to ~500 GB/s, and the two Blackwell GPUs together contribute up to ~384 GB of HBM3e memory (192 total GB per GPU). In total, a GB200 Superchip exposes roughly ~900 GB of memory of coherent, unified memory accessible by the GPUs and CPUs in a unified address space.

简而言之，每个超级芯片拥有近一太字节的快速统一内存可供使用。这对巨型AI模型来说是游戏规则的改变者。在旧系统中，单个GPU可能被限制在< 100 GB的内存，这意味着超过此大小的模型必须被分区或卸载到较慢的存储。在这里，GPU可以无缝地利用CPU的内存作为扩展。

> To put it simply, each superchip has nearly a terabyte of fast, unified memory at its disposal. This is a game changer for giant AI models. In older systems, a single GPU might be limited to < 100 GB of memory, which meant models larger than that had to be partitioned or offloaded to slower storage. Here, a GPU can seamlessly utilize the CPU's memory as an extension.

如果神经网络层或大型嵌入表不适合GPU的本地HBM，它可以驻留在CPU的内存中，GPU仍然可以通过NVLink-C2C与其协同工作。从程序员的角度来看，统一虚拟地址空间和一致性简化了正确性。但是，为了性能，应该使用异步预取和分段流水线等技术显式管理放置和内存移动。使用NVLink-C2C访问LPDDR5X比直接访问HBM具有更高的延迟和大致低一个数量级的带宽。

> If a neural network layer or a large embedding table doesn't fit in the GPU's local HBM, it can reside in the CPU's memory, and the GPU will still be able to work with it across NVLink-C2C. From a programmer's perspective, the unified virtual address space and coherence simplify correctness. However, for performance, one should explicitly manage placement and memory movement using techniques such as asynchronous prefetch and staged pipelines. Accessing LPDDR5X using NVLink-C2C has higher latency and roughly an order-of-magnitude lower bandwidth than accessing HBM directly.

GPU内存仍然比CPU内存快得多，更接近GPU核心——你可以将CPU内存视为一个大但稍慢的扩展。访问LPDDR5X中的数据不如GPU上的HBM快。它的带宽大约低10倍，延迟更高。智能运行时会将最常用的数据保留在HBM中，并使用CPU的LPDDR5X存储溢出或不太关键的数据。关键点是，溢出不再需要通过NVMe SSD或跨网络。

> GPU memory is still much faster and closer to the GPU cores than CPU memory—you can think of the CPU memory as a large but somewhat slower extension. Accessing data in LPDDR5X isn't as quick as HBM on the GPU. It's on the order of 10× lower bandwidth and higher latency. A smart runtime will keep the most frequently used data in HBM and use the CPU's LPDDR5X for overflow or less speed-critical data. The key point is that overflow no longer requires going out to NVMe SSD or across a network.

GPU可以以大约900 GB/s的速度从CPU RAM获取数据（每个方向450 GB/s），虽然比HBM慢，但比从NVMe SSD存储获取快得多。这种灵活性至关重要，因为这意味着一个500 GB大小的模型（对于单个GPU的HBM来说太大）仍然可以完全放置在一个超级芯片模块内，访问组合的192（180可用）GB HBM和约500 GB的CPU内存。该模型可以在不跨多个GPU分区的情况下运行。GPU只会在需要时透明地从CPU内存中提取额外数据。

> The GPU can fetch from CPU RAM at perhaps 900 GB/s (450 GB/s per direction), which, while slower than HBM, is much faster than fetching from NVMe SSD storage. This flexibility is critical, as it means a model that is, say, 500 GB in size (too large for a single GPU's HBM) can still be placed entirely within one superchip module with access to a combined 192 (180 usable) GB in HBM and ~500 GB of CPU memory. This model can run without partitioning the model across multiple GPUs. The GPU would just transparently pull the extra data from CPU memory when needed.

本质上，只要总模型适合超级芯片的组合CPU + GPU内存，内存大小就不再是适应超大型模型的硬限制。许多研究人员在模型不适合GPU时遇到了可怕的"内存不足"错误——这种架构旨在显著推后这一边界。

> In essence, memory size ceases to be a hard limit for fitting ultralarge models, as long as the total model fits within the combined CPU + GPU memory of the superchip. Many researchers have faced the dreaded "out of memory" errors when models don't fit on a GPU—this architecture is designed to push that boundary out significantly.

## 2.2 NVIDIA Grace CPU

Grace CPU本身绝非等闲之辈。它是由NVIDIA专为带宽和效率定制的ARM Neoverse V2 CPU。它在超级芯片中的工作是处理通用任务、预处理并向GPU提供数据，以及管理附着在其上的大量内存。它以适中的时钟速度运行，但通过巨大的内存带宽——高达约500 GB/s到其LPDDR5X内存——以及大量缓存（包括超过100 MB的L3缓存）来弥补。

> The Grace CPU itself is no sloth. It's an ARM Neoverse V2 CPU custom-designed by NVIDIA for bandwidth and efficiency. Its job in the superchip is to handle general-purpose tasks, preprocess and feed data to the GPUs, and manage the mountain of memory attached to it. It runs at a modest clock speed but makes up for it with huge memory bandwidth—up to ~500 GB/s to its LPDDR5X memory—and lots of cache, including over 100 MB of L3 cache.

其理念是，在向GPU推送数据时，CPU永远不应成为瓶颈。它可以从存储流式传输数据或执行即时数据转换（如分词或数据增强），通过NVLink-C2C非常高效地向GPU提供数据。如果你的工作负载的一部分在CPU上更好，Grace核心可以处理这些，并使结果立即可被GPU访问。

> The philosophy is that the CPU should never become a bottleneck when shoveling data to the GPUs. It can stream data from storage or perform on-the-fly data transformations like tokenization or data augmentation—feeding the GPUs through NVLink-C2C very efficiently. If part of your workload is better on the CPU, the Grace cores can tackle that and make the results immediately accessible by the GPUs.

这是一种和谐的耦合，CPU在GPU较弱的领域扩展了GPU的能力，如随机内存访问或控制密集型代码。而GPU加速了CPU无法跟上的数值计算。

> This is a harmonious coupling in which the CPU extends the GPU's capabilities in areas where GPUs are weaker, like random memory accesses or control-heavy code. And the GPUs accelerate the number-crunching where CPUs can't keep up.

CPU和GPU之间的低延迟链路意味着它们可以在没有通常开销的情况下交换任务。例如，从CPU启动GPU内核可以比在传统系统上快得多，因为命令不必穿越慢速PCIe总线。CPU和GPU本质上在同一块板上。这类似于调用快速本地函数与较慢的远程函数。接下来，让我们谈谈Blackwell GPU，超级芯片的强力引擎。

> The low-latency link between the CPU and GPUs means they can trade tasks without the usual overhead. For example, launching a GPU kernel from the CPU can happen much faster than on a traditional system, since the command doesn't have to traverse a slow PCIe bus. The CPU and GPU are essentially on the same board. This is similar to calling a fast local function versus a slower remote function. Next, let's talk about the Blackwell GPU, the brute-force engine of the superchip.

## 2.3 NVIDIA Blackwell "双裸片" GPU

Blackwell是NVIDIA对这一GPU代的代号，它在计算能力和内存方面都代表了相对于前一代Hopper（H100）GPU的显著飞跃。Blackwell B200和B300 "Ultra" GPU不是单芯片。相反，它们使用多芯片模块（MCM）设计，将两个GPU裸片放置在单个模块中。因此，Blackwell被称为双裸片GPU（见图2-2）。

> Blackwell is NVIDIA's codename for this GPU generation, and it represents a significant leap over the previous Hopper (H100) GPUs in both compute horsepower and memory. The Blackwell B200 and B300 "Ultra" GPU are not single chips. Instead, they use a multichip module (MCM) design with two GPU dies placed in a single module. As such, Blackwell is called a dual-die GPU (see Figure 2-2).

![图2-2 Blackwell双裸片多芯片模块（MCM）设计](../assets/images/ch02/fig2_52_1.png)

这种小芯片方法将通常是一个巨大GPU的东西分成较小的GPU裸片——用超快的封装内裸片到裸片互连将它们连接起来。为什么要这样做？因为单片裸片受到制造限制，因为硅片上芯片的大小有限制。通过将两个物理GPU裸片组合到单个模块中，NVIDIA可以使模块的总晶体管预算翻倍。

> This chiplet approach splits what would normally be one enormous GPU into smaller GPU dies—linking them together with a superfast, on-package die-to-die interconnect. Why do this? Because a single monolithic die is limited by manufacturing because there's a limit to how large you can make a chip on silicon. By combining two physical GPU dies into a single module, NVIDIA can double the total transistor budget for the module.

对于Blackwell B200 MCM，每个GPU裸片约有1040亿个晶体管和96 GB HBM3e内存。组合的GPU模块约有2080亿个晶体管和每个B200 GPU总共192（180可用）GB内存。相比之下，Hopper H100 GPU有约800亿个晶体管和80 GB HBM3（相对于Blackwell的HBM3e）内存。因此，Blackwell的B200使晶体管数量增加了一倍多，内存大小增加了约2.4倍。

> For the Blackwell B200 MCM, each GPU die has about 104 billion transistors and 96 GB HBM3e memory. The combined GPU module has around 208 billion transistors and 192 (180 usable) GB total memory per B200 GPU. By comparison, the Hopper H100 GPU had ~80 billion transistors and 80 GB HBM3 (versus Blackwell's HBM3e) memory. As such, Blackwell's B200 more than doubles transistor count and ~2.4× increases memory size.

Blackwell的两个GPU裸片使用称为NV-HBI（高带宽接口）的专用高速10 TB/s裸片到裸片互连进行通信。这使得模块中的两个GPU裸片可以作为单个统一GPU运行。运行在其上的软件层只看到一个GPU。

> Blackwell's two GPU dies communicate using a specialized, high-speed 10 TB/s die-to-die interconnect called NV-HBI (High-Bandwidth Interface). This lets the two GPU dies in the module function as a single unified GPU. The software layer running on top of it sees only a single GPU.

从系统的角度来看，Blackwell GPU是一个单一模块或设备，具有大容量内存池（192 [180可用] GB HBM3e）和大量执行单元，但在底层它是两个协同工作的芯片。NVIDIA的软件和调度确保工作在两个GPU裸片之间平衡，内存访问是一致的。这使开发人员能够在很大程度上忽略这种复杂性，因为它们表现为一个GPU，正如NVIDIA所预期的那样。

> From the system's perspective, a Blackwell GPU is one single module, or device, with a large pool of memory (192 [180 usable] GB HBM3e) and a ton of execution units, but under the hood it's two chips working in tandem. NVIDIA's software and scheduling ensure that work is balanced across the two GPU dies and memory accesses are coherent. This allows developers to largely ignore this complexity, as they appear as one GPU, as NVIDIA intended.

每个Blackwell B200 GPU模块在两个GPU裸片（每个96 GB）上组合了192（180可用）GB的HBM3e内存，分为8-Hi堆栈。8-Hi HBM3e堆栈通过垂直堆叠八个DRAM裸片构建——每个3 GB——每个堆栈总共24 GB。

> Each Blackwell B200 GPU module has 192 (180 usable) GB of HBM3e memory combined across the two GPU dies (96 GB each) and divided into 8-Hi stacks. An 8-Hi HBM3e stack is built by vertically stacking eight DRAM dies—each 3 GB—for a total of 24 GB per stack.

B200 GPU使用八个这样的堆栈（每个裸片四个）提供192（180可用）GB（192 GB = 8堆栈 × 每堆栈24 GB）的封装内内存。与前一代Hopper GPU相比，这增加了每GPU堆栈数量和容量——并为模型参数、激活、梯度和输入数据提供了更多空间。

> The B200 GPU uses eight of these stacks (four per die) to provide 192 (180 usable) GB (192 GB = 8 stacks × 24 GB per stack) of on-package memory. This increases the per-GPU stack count and capacity compared to the previous generation Hopper GPUs—and gives more headroom for model parameters, activations, gradients, and input data.

内存也更快，因为Blackwell的B200 HBM3e每个GPU的总带宽高达约8 TB/s。相比之下，Hopper使用前一代HBM3，每个GPU提供约3.35 TB/s。因此，Blackwell的内存带宽吞吐量比Hopper高约2.4倍。

> The memory is also faster, as Blackwell's B200 HBM3e has an aggregate bandwidth up to roughly 8 TB/s per GPU. For comparison, the Hopper uses the previous generation HBM3, which delivers ~3.35 TB/s per GPU. As such, Blackwell's memory bandwidth throughput is roughly 2.4× higher than Hopper's.

以每秒8太字节的速度提供数据，Blackwell GPU核心保持忙碌地处理巨大矩阵，而不经常因等待数据而停顿。NVIDIA还增强了片上缓存，Blackwell总共有126 MB的L2缓存（每个裸片63 MB）。这个缓存是GPU上的一个小但超快的内存，保存最近使用的数据。

> Feeding data at 8 terabytes per second, the Blackwell GPU cores are kept busy crunching on huge matrices without frequently stalling to wait for data. NVIDIA also beefed up on-chip caching, as Blackwell has a total of 126 MB of L2 cache (63 MB per die). This cache is a small but ultrafast memory on the GPU that holds recently used data.

通过将L2缓存大小比Hopper的50 MB L2缓存增加超过2.5倍，Blackwell可以将更多神经网络权重或中间结果保留在芯片上，避免额外的HBM访问。这再次有助于确保GPU的计算单元很少因缺乏数据而停顿。

> By increasing the L2 cache size by more than 2.5× compared to Hopper's 50 MB L2 cache, Blackwell can keep more of the neural network weights or intermediate results on chip, avoiding extra trips out to HBM. This again helps ensure the GPU's compute units are seldom starved for data.

接下来，让我们展示Blackwell GPU如何与专用的一组低精度Tensor Core配对——以及来自NVIDIA的transformer优化硬件和软件API，称为Transformer Engine。像PyTorch这样的框架和像vLLM这样的推理引擎通过使用CUDA、CUTLASS和OpenAI的Triton等库支持这些优化，我们将在后面的章节中讨论这些。

> Next, let's show how the Blackwell GPU is paired with a dedicated set of reduced-precision Tensor Cores—as well as transformer-optimized hardware and software APIs from NVIDIA called the Transformer Engine. Frameworks, like PyTorch and inference engines like vLLM, support these optimizations by using libraries like CUDA, CUTLASS, and OpenAI's Triton, which we talk about in later chapters.

## 2.4 NVIDIA GPU Tensor Core和Transformer Engine

说到计算单元，Blackwell引入了专门针对AI工作负载的增强功能。核心是NVIDIA的Tensor Core技术和Transformer Engine（TE）。Tensor Core是GPU每个流式多处理器（SM）内的专用单元，可以以非常高的速度执行矩阵乘法操作。

> Speaking of compute units, Blackwell introduces enhancements specifically aimed at AI workloads. Central to this is NVIDIA's Tensor Core technology and the Transformer Engine (TE). Tensor Cores are specialized units within each streaming multiprocessor (SM) of the GPU that can perform matrix multiplication operations at very high speed.

Tensor Core在前几代中就已存在，但Blackwell的Tensor Core支持更多数值格式，包括极低精度的格式，如8位和4位浮点。低精度背后的想法很简单。通过使用更少的位来表示数字，你可以同时执行更多操作——更不用说你的内存可以更持久，因为表示相同数字所需的位更少。这假设你的算法可以容忍数值精度的一点损失。如今，许多AI算法在设计时就考虑了低精度数值格式。

> Tensor Cores were present in prior generations, but Blackwell's Tensor Cores support even more numerical formats, including extremely low-precision ones like 8-bit and 4-bit floating point. The idea behind lower precision is simple. By using fewer bits to represent numbers, you can perform more operations at the same time—not to mention your memory goes further since fewer bits are used to represent the same numbers. This assumes that your algorithm can tolerate a little loss in numerical precision. These days, a lot of AI algorithms are designed with low-precision numerical formats in mind.

NVIDIA开创了TE，可以在深度学习中自动调整和使用混合精度，其中关键层使用较高精度（FP16或BF16），较不关键的层使用FP8。TE自动优化精度的平衡，目标是在较低精度下保持模型的准确性。

> NVIDIA pioneered the TE to automatically adjust and use mixed precision in deep learning where critical layers use higher precision (FP16 or BF16) and less critical layers use FP8. TE automatically optimizes the balance of precision with the goal of maintaining the model's accuracy at the lower precision.

在Hopper代中，TE首次引入了FP8支持，使吞吐量比FP16翻倍。Blackwell通过引入NVIDIA FP4（NVFP4）更进一步，这是一种4位浮点格式，使用的位数是FP8的一半。FP4非常小，它可能使FP8的计算吞吐量翻倍。图2-3显示了FP8和FP4相对于FP16的加速比。

> In the Hopper generation, the TE first introduced FP8 support, which doubled the throughput versus FP16. Blackwell takes it one step further by introducing NVIDIA FP4 (NVFP4), a 4-bit floating-point format that uses half the number of bits of FP8. FP4 is so small that it can potentially double the compute throughput of FP8. Figure 2-3 shows the relative speedup of FP8 and FP4 compared to FP16.

![图2-3 FP8和FP4相对于FP16的加速比](../assets/images/ch02/fig2_56_1.png)

整个NVL72机柜（72个GPU）在4位精度下的理论Tensor Core吞吐量超过1.4 exaFLOPS（即1.4 × 10¹⁸）。这是一个令人难以置信的数字，使这个单一机柜进入了世界最快超级计算机的领域——尽管是在低FP4精度下。即使实际工作负载并不总是达到那个峰值，这种能力是存在的，这是令人惊叹的。

> An entire NVL72 rack (72 GPUs) has a theoretical Tensor Core throughput over 1.4 exaFLOPS (that's 1.4 × 10¹⁸) in 4-bit precision. This is a mind-boggling number that puts this single rack in the realm of the world's fastest supercomputers—albeit at low FP4 precision. Even if real-world workloads don't always hit that peak, the capability is there, which is astonishing.

现代GPU使用添加了NVFP4支持以及改进的缩放和校准的TE。在实践中，你通过在PyTorch等框架中使用其内核和模块来采用TE。这样，FP8和NVFP4在保持准确性的情况下被应用。这不是所有框架中完全自动的逐层决策。

> Modern GPUs use a TE that adds NVFP4 support together with improved scaling and calibration. In practice, you adopt TE by using its kernels and modules in frameworks such as PyTorch. This way, FP8 and NVFP4 are applied when they preserve accuracy. This is not a fully automatic per-layer decision in all frameworks.

高级技术包括在训练和推理期间动态更改神经网络每一层的精度。目标是为每一层使用仍能保持模型准确性的最低精度。例如，TE可能将神经网络的前几层保持在FP16，因为早期层可能对噪声敏感。但是，基于启发式方法，它可能决定对更容忍的后续层使用FP8或FP4——或者对于高精度不太关键的大型嵌入矩阵。

> Advanced techniques include dynamically changing the precision for each layer of a neural network during training and inference. The goal is to use the lowest precision that will still preserve model accuracy for each of those layers. For example, the TE might keep the first layers of a neural net in FP16 since early layers can be sensitive to noise. But, based on heuristics, it could decide to use FP8 or FP4 for later layers that are more tolerant—or for giant embedding matrices where high precision isn't as critical.

所有这些都可以在NVIDIA库和PyTorch等AI框架的后台发生。作为用户，你只需启用混合精度，结果是一个基本上"免费"获得的巨大加速。我们将在第9章讨论混合精度，但只需知道许多LLM今天出于这个原因使用混合精度。这些降低的精度提高了相对于FP16和FP32的训练速度——并减少了精度损失。Blackwell旨在使FP8和FP4易于访问和高效。

> All of this can happen under the hood in NVIDIA libraries and AI frameworks like PyTorch. As a user, you just enable mixed precision, and the result is a huge speedup that essentially comes "for free." We'll discuss mixed precision in Chapter 9, but just know that many LLMs today use mixed precision for this reason. These reduced precisions improve training speed compared to FP16 and FP32—and reduce accuracy loss. Blackwell was built to make FP8 and FP4 accessible and efficient.

这些降低精度的格式也减少了内存使用。使用FP4使每个参数所需的内存比FP8减半（FP8使FP16内存使用减半），这意味着你可以将更大的模型装入GPU的内存。

> These reduced-precision formats reduce memory usage as well. Using FP4 halves the memory needed per parameter compared to FP8 (and FP8 halves FP16 memory usage), meaning you can pack an even larger model into the GPU's memory.

NVIDIA实际上押注于AI的未来在于低精度算术，并赋予Blackwell在此方面卓越的能力。这对于大规模模型的推理服务尤为关键，其中吞吐量（每秒token数）和延迟至关重要。

> NVIDIA has effectively bet on AI's future being in lower precision arithmetic and has given Blackwell the ability to excel at it. This is especially critical for inference serving of massive models, where throughput (tokens per second) and latency are paramount.

为了说明从Hopper到Blackwell的代际飞跃，NVIDIA报告称，基于H100的系统对于大型1.8万亿参数MoE模型每个GPU只能生成约3.4个token每秒——第一个token的延迟超过5秒。这对于交互式使用来说太慢了。

> To illustrate the generational leap forward from Hopper to Blackwell, NVIDIA reported an H100-based system could generate only about 3.4 tokens per second per GPU for a large 1.8-trillion-parameter MoE model—with over 5 seconds of latency for the first token. This is too slow for interactive use.

基于Blackwell的系统（NVL72）运行相同的模型，每个GPU约150个token每秒，第一个token延迟低至约50毫秒。这大约是相对于Hopper代的30倍实时吞吐量改进。NVL72使这个巨大的模型能够提供实时响应——为更多低延迟用例打开了大门。

> The Blackwell-based system (NVL72) ran the same model with around 150 tokens per second per GPU and a low first-token latency of ~50 milliseconds. That is roughly 30× the real-time throughput improvement over the Hopper generation. The NVL72 allowed this massive model to serve real-time responses—opening it up to many more low-latency use cases.

这种加速来自原始FLOPS、更快GPU的组合、低精度（FP4）使用以及NVLink互连保持GPU数据供应充足。它强调了跨越计算和通信的整体设计如何转化为实际性能收益。

> This speedup came from raw FLOPS, the combination of faster GPUs, lower precision (FP4) usage, and the NVLink interconnect keeping the GPUs fed with data. It underscores how a holistic design that spans across both compute and communication can translate into real-world performance gains.

本质上，Blackwell GPU比其前身更强大、更智能、数据供应更充足。由于Tensor Core、TE和低精度，它们更快地处理数学运算。此外，系统架构确保通过巨大的内存带宽、大型缓存和NVLink快速提供数据。

> In essence, Blackwell GPUs are more powerful, smarter, and better fed with data than their predecessors. They chew through math faster, thanks to Tensor Cores, TE, and low precision. Additionally, the system architecture ensures that data is made available quickly thanks to huge memory bandwidth, large caches, and NVLink.

在继续之前，让我们快速讨论GPU内部的层次结构，因为这对于理解后面的性能调优很有用。

> Before moving on, let's quickly discuss the hierarchy inside the GPU, as this is useful to understand performance tuning later.

## 2.5 流式多处理器、线程和Warp

每个Blackwell GPU，像其前身一样，由许多流式多处理器（SM）组成。可以将这些视为GPU的"核心"，如图2-4所示。

> Each Blackwell GPU, like its predecessors, consists of many streaming multiprocessors (SMs). Think of these like the "cores" of the GPU, as shown in Figure 2-4.

![图2-4 比较CPU核心与GPU核心](../assets/images/ch02/fig2_59_1.png)

每个SM包含一堆算术单元（用于FP32、INT32等）、用于矩阵数学的Tensor Core、用于内存操作的加载/存储单元，以及一些用于超越数学等事情的特殊功能单元。GPU还有自己的小型超快内存池，包括寄存器、共享内存和L1缓存。

> Each SM contains a bunch of arithmetic units (for FP32, INT32, etc.), Tensor Cores for matrix math, load/store units for memory operations, and some special function units for things like transcendental math. The GPU also has its own small pool of superfast memory, including registers, shared memory, and L1 cache.

SM以称为warp的固定大小组执行线程，每个warp包含恰好32个线程，它们以锁步方式执行完全相同的指令。这称为单指令多线程（SIMT）执行模型。

> An SM executes threads in fixed-size groups known as warps, with each warp containing exactly 32 threads that execute the exact same instructions in lockstep. This is called the single instruction, multiple threads (SIMT) execution model.

SM并行执行许多活动warp，以帮助覆盖线程等待从全局内存访问数据的延迟。考虑一个SM同时有数十个warp（数百个线程）在运行。如果一个warp正在等待内存获取，另一个warp可以运行。这称为延迟隐藏。我们将在整本书中重新讨论延迟隐藏。这是你的调优工具箱中非常重要的性能优化工具。

> SMs execute many active warps in parallel to help cover the latency of a thread waiting on data accessed from global memory. Consider an SM having dozens of warps (hundreds of threads) in flight concurrently. If one warp is waiting on a memory fetch, another warp can run. This is called latency hiding. We will revisit latency hiding throughout the book. This is a very important performance-optimization tool to have in your tuning toolbox.

像Blackwell这样的高端GPU将有数百个SM。每个SM能够同时运行数千个线程。这就是我们如何在单个GPU上获得数万个活动线程。所有这些SM共享我们之前提到的126 MB L2缓存，并共享连接到HBM的内存控制器。内存层次结构包含寄存器（每线程）→ 共享内存（每线程块，在每个SM上）→ L1缓存（每SM）→ L2缓存（在GPU上的所有SM之间共享）→ HBM内存（片外），如图2-5所示。

> A high-end GPU like Blackwell will have hundreds of SMs. Each SM is capable of running thousands of threads concurrently. This is how we get tens of thousands of active threads onto a single GPU. All those SMs share a 126 MB L2 cache, as we mentioned earlier, and share the memory controllers that connect to the HBM. The memory hierarchy contains registers (per thread) → shared memory (per thread block, on each SM) → L1 cache (per SM) → L2 cache (shared across all SMs on the GPU) → HBM memory (off chip), as shown in Figure 2-5.

![图2-5 GPU内存层次结构](../assets/images/ch02/fig2_61_1.png)

为了获得最佳性能，数据需要尽可能保持在层次结构的高层。如果每个操作都以8 TB/s的速度访问HBM，GPU将因访问片外内存的延迟增加而过于频繁地停顿。通过将可重用数据保留在SM本地内存或L2缓存中，GPU可以实现巨大的吞吐量。Blackwell架构的缓存和带宽翻倍正是为了让GPU巨兽保持饱足和快乐。

> For best performance, data needs to stay as high in that hierarchy as possible. If every operation went out to HBM even at 8 TB/s, the GPU would stall too often due to the increased latency of accessing off-chip memory. By keeping reusable data in SM local memory or L2 cache, the GPU can achieve enormous throughput. The Blackwell architecture's doubling of cache and bandwidth is aimed exactly at keeping the GPU beast fed and happy.

作为性能工程师，我们将看到许多示例，其中内核的性能受计算以及内存流量和吞吐量的限制。NVIDIA显然设计了Blackwell，使得对于许多AI工作负载，FLOPS和内存带宽之间的平衡是良好匹配的。

> As performance engineers, we'll see many examples where a kernel's performance is bound by compute as well as memory traffic and throughput. NVIDIA clearly designed Blackwell so that, for many AI workloads, the balance between FLOPS and memory bandwidth is well-matched.

Blackwell的设计平衡了计算和内存，因此对于许多AI内核，GPU可以以最少的停顿继续计算。在实践中，优化良好的密集数学操作可以从片上内存重用数据，接近峰值FLOPS，而不会严重受内存限制。

> Blackwell's design balances compute and memory so that for many AI kernels the GPUs can keep computing with minimal stalls. In practice, well-optimized dense math operations can reuse data from on-chip memory to approach peak FLOPS without being severely memory bound.

所有这些意味着，给定优化良好的代码，GPU通常会忙于计算而不是等待数据。请注意，某些操作如大型归约或随机内存访问仍然可能受内存限制，但更新的GPU、内存和互连硬件使这不再那么成问题。

> All of this means that, given well-optimized code, the GPUs will often be busy computing rather than waiting on data. Note that certain operations like huge reductions or random memory accesses can still be memory bound, but the updated GPU, memory, and interconnect hardware make this a bit less of an issue.

## 2.6 超大规模网络：将许多GPU视为一个

将两个GPU和一个CPU封装到超级芯片中为我们提供了一个极其强大的节点。下一个挑战是将许多这样的超级芯片连接起来，以扩展到更大的模型训练。

> Packing two GPUs and a CPU into a superchip gives us an incredibly powerful node. The next challenge is connecting many of these superchips together to scale out to even larger model training.

NVIDIA使用GB200/GB300超级芯片提供大型机柜配置，称为NVL72系统。NVL72代表一个具有72个Blackwell GPU和36个Grace CPU的系统——全部通过NVLink互连。这本质上是单个机柜中的AI超级计算机。

> NVIDIA provides a large rack configuration using GB200/GB300 Superchips called the NVL72 system. NVL72 stands for a system with 72 Blackwell GPUs—and 36 Grace CPUs—all interconnected with NVLink. This is essentially an AI supercomputer in a single rack.

GB200/GB300 NVL72构建为18个计算节点，其中每个节点包含两个GB200/GB300超级芯片，总共四个Blackwell GPU + 每个计算节点两个Grace CPU，如图2-6所示。

> The GB200/GB300 NVL72 is built as 18 compute nodes in which each node contains two GB200/GB300 Superchips for a total of four Blackwell GPUs + two Grace CPUs per compute node, as shown in Figure 2-6.

![图2-6 GB200/GB300 NVL72机柜内的1U计算托盘](../assets/images/ch02/fig2_63_1.png)

在这里，每个超级芯片模块有一个Grace CPU和两个Blackwell GPU（每个B200是双裸片MCM）。NVL72有18个这样的托盘连接在一起。通过将18个计算节点连接在一起，GB200/GB300 NVL72连接了72个Blackwell GPU（18节点 × 4 GPU）和36个Grace CPU（18节点 × 2 CPU）形成一个强大的统一CPU-GPU集群。

> Here, each superchip module has one Grace CPU and two Blackwell GPUs (each B200 is a dual-die MCM). The NVL72 has 18 of these trays linked together. By connecting the 18 compute nodes together, the GB200/GB300 NVL72 links 72 Blackwell GPUs (18 nodes × 4 GPUs) and 36 Grace CPUs (18 nodes × 2 CPUs) together to form a powerful, unified CPU-GPU cluster.

NVL72的有趣之处在于，每个GPU都可以通过NVLink交换架构在单个NVLink域内以非常高的速度与任何其他GPU通信。NVIDIA使用GPU上的NVLink 5连接和称为NVSwitch的专用交换硅芯片的组合实现了这一点。

> The interesting thing about the NVL72 is that every GPU can talk to any other GPU through the NVLink Switch fabric at very high speed within a single NVLink domain. NVIDIA achieved this using a combination of NVLink 5 connections on the GPUs and a dedicated switch silicon called NVSwitch.

### 2.6.1 NVLink和NVSwitch

每个Blackwell GPU暴露18个NVLink 5端口。总双向NVLink带宽为每GPU 1.8 TB/s（18个NVLink链路 × 100 GB/s双向），NVL72将所有端口连接到NVLink交换系统。每个NVLink交换托盘提供144个100 GB/s的NVLink端口。在九个托盘中，每个GPU的18个NVLink 5链路每个连接到一个NVSwitch芯片，因此72个GPU以全双分带宽完全连接。

> Each Blackwell GPU exposes 18 NVLink 5 ports. Aggregate bidirectional NVLink bandwidth is 1.8 TB/s per GPU (18 NVLink links × 100 GB/s bidirectional) with the NVL72 wiring all ports to the NVLink Switch System. Each NVLink switch tray delivers 144 NVLink ports at 100 GB/s. Across the nine trays, each GPU's 18 NVLink 5 links are wired one per NVSwitch chip so the 72 GPUs are fully connected at full bisection bandwidth.

这是前一代Hopper GPU使用的每GPU NVLink带宽的两倍。Hopper H100使用18个NVLink 4端口，但以NVLink 5一半的速度运行。通过NVLink的GPU间延迟在个位数微秒范围内。

> This is double the per-GPU NVLink bandwidth of the previous generation used by Hopper GPUs. The Hopper H100 uses 18 NVLink 4 ports but runs at half the speed of NVLink 5. Inter-GPU latency over NVLink is in the single-digit microsecond range.

GPU通过NVSwitch芯片在网络中布线。NVSwitch本质上是一个类似于网络交换机的交换芯片，但它是专门为NVLink构建的。这意味着任何GPU都可以通过NVLink交换系统中的一个交换阶段以全双分带宽到达任何其他GPU。这个单阶段属性在单个NVL72机柜内成立，因为每个GPU使用其18个NVLink链路连接到18个NVSwitch芯片，通过单个交换机启用路径。图2-7显示了NVL72中使用的NVLink交换托盘。

> The GPUs are cabled in a network through NVSwitch chips. NVSwitch is essentially a switching chip similar to a network switch, but it's built specifically for NVLink. This means any GPU can reach any other GPU through one switch stage in the NVLink Switch System at full bisection bandwidth. This one-stage property holds true within a single NVL72 rack because each GPU uses its 18 NVLink links to connect to the 18 NVSwitch chips, enabling a path through a single switch. Figure 2-7 shows an NVLink Switch tray used in NVL72.

![图2-7 NVL72内部的一个NVLink交换托盘](../assets/images/ch02/fig2_66_1.png)

每个交换托盘包含两个NVSwitch芯片和多个高速端口。NVL72机柜由9个这样的交换托盘和18个计算托盘组成，如图2-8所示。

> Each switch tray contains two NVSwitch chips and multiple high-speed ports. The NVL72 rack comprises 9 such switch trays and 18 compute trays, as shown in Figure 2-8.

![图2-8 NVL72机柜内的九个托盘NVSwitch系统](../assets/images/ch02/fig2_68_1.png)

由于9个交换托盘中的每个包含两个NVSwitch芯片，NVL72系统中总共有18个NVSwitch芯片。网络安排为全交叉开关，使得每个GPU连接到每个NVSwitch，每个NVSwitch连接到每个GPU。这提供了任何GPU对之间的高带宽路径。

> Since each of the 9 switch trays contains two NVSwitch chips, the total is 18 NVSwitch chips in the NVL72 system. The network is arranged as a full crossbar such that every GPU is connected to every NVSwitch, and every NVSwitch is connected to every GPU. This provides a high-bandwidth path between any pair of GPUs.

每个交换托盘暴露144个NVLink端口以完全连接每个GPU上的18个NVLink链路。具体来说，每个GPU使用其18个NVLink链路连接到18个NVSwitch芯片（每个交换机一个链路）。这意味着任何GPU可以在一跳内到达任何其他GPU（GPU → NVSwitch → GPU），沿途具有巨大带宽。图2-9显示了具有72个完全连接的GPU（36个GB200超级芯片）和18个NVSwitch的完整NVL72架构。

> Each switch tray exposes 144 NVLink ports to fully connect the 18 NVLink links on each GPU. Concretely, each GPU uses its 18 NVLink links to connect to the 18 NVSwitch chips (one link to each switch). This means any GPU can reach any other GPU in one hop (GPU → NVSwitch → GPU), with enormous bandwidth along the way. Figure 2-9 shows the full NVL72 architecture with 72 fully connected GPUs (36 GB200 superchips) and 18 NVSwitches.

![图2-9 每个GPU连接到每个NVSwitch](../assets/images/ch02/fig2_70_1.png)

整个72 GPU网络的总双分带宽在NVL72机柜内约为130 TB/s。作为参考，这比类似规模的顶级InfiniBand集群高出许多倍。该设计暴露了一个完全连接的高带宽架构，具有跨GPU的全局地址空间。这允许高效的集合操作和单边操作，同时保留对同步和一致性的显式软件控制。

> The aggregate bisection bandwidth across the entire 72-GPU network is about 130 TB/s within an NVL72 rack. For perspective, that is many times higher than even a top-end InfiniBand cluster of similar scale. The design exposes a fully connected, high-bandwidth fabric with a global address space across GPUs. This allows efficient collectives and one-sided operations while preserving explicit software control over synchronization and consistency.

### 2.6.2 多GPU编程

从编程模型的角度来看，一个GPU可以使用点对点和分区全局地址空间（PGAS）模型（如NVIDIA SHMEM（NVSHMEM），NVIDIA的GPU加速OpenSHMEM实现）通过NVLink直接访问另一个GPU的内存。

> From a programming model standpoint, one GPU can directly access another GPU's memory over NVLink using peer-to-peer and partitioned global address space (PGAS) models such as NVIDIA SHMEM (NVSHMEM), NVIDIA's GPU-accelerated OpenSHMEM implementation.

有一个全局地址空间，但GPU缓存在GPU之间不是全局一致的。只有CPU-GPU路径上的NVLink-C2C是缓存一致的。NCCL和NVSHMEM等软件栈提供正确多GPU访问所需的同步和排序。

> There is a global address space, but GPU caches are not globally coherent across GPUs. Only the CPU–GPU path over NVLink-C2C is cache coherent. Software stacks such as NCCL and NVSHMEM provide the synchronization and ordering required for correct multi-GPU access.

结合硬件缓存一致性和软件同步技术，NVL72可以被视为本质上一个大GPU。

> Combined, hardware cache coherency and software synchronization techniques allow the NVL72 to be seen as essentially one big GPU.

远程直接内存访问（RDMA）是一种网络技术，可以在InfiniBand和融合以太网上的RDMA（RoCE）传输之间实现主机之间的直接零拷贝内存传输。可选的远程原子操作由InfiniBand贸易协会（IBTA）为InfiniBand和RoCE定义。

> Remote direct memory access (RDMA) is a network technology that enables direct, zero-copy memory transfers between hosts across InfiniBand and RDMA over Converged Ethernet (RoCE) transports. Optional remote atomic operations are defined by the InfiniBand Trade Association (IBTA) for InfiniBand and RoCE.

GPUDirect RDMA是NVIDIA的RDMA协议实现，使网络接口控制器（NIC）能够注册GPU内存并使用nvidia-peermem驱动程序直接向GPU内存执行RDMA。这允许GPU在不涉及CPU的情况下跨节点交换数据和执行原子操作。这允许NIC直接向GPU内存执行DMA，而无需通过主机RAM进行暂存。

> GPUDirect RDMA, NVIDIA's implementation of the RDMA protocol, enables network interface controllers (NICs) to register GPU memory and perform RDMA directly to and from GPU memory using the nvidia-peermem driver. This allows GPUs to exchange data and execute atomic operations across nodes without involving the CPU. This allows NICs to perform direct DMA to and from GPU memory without staging through host RAM.

跨节点的远程原子操作和单边操作由NVSHMEM等上层库提供，这些库在RDMA传输上实现这些语义。请注意，GPUDirect RDMA提供直接数据路径，而不是原子API本身。分布式训练和推理工作负载需要在许多GPU之间频繁同步和交换信息。

> Remote atomics and one-sided operations across nodes are provided by upper-layer libraries such as NVSHMEM, which implement these semantics over RDMA transports. Note that GPUDirect RDMA supplies the direct data path rather than the atomic APIs themselves. Distributed training and inference workloads need to synchronize and exchange information frequently across many GPUs.

传统上，GPU位于不同的计算节点和机柜中。因此，同步可以通过相对较慢的网络链路（如InfiniBand和以太网）进行。这通常是扩展到许多GPU以支持大型AI模型时的瓶颈。

> Traditionally, the GPUs are in different compute nodes and racks. As such, synchronization can happen over relatively slow network links like InfiniBand and Ethernet. This is often the bottleneck when scaling across many GPUs to support large AI models.

使用NVL72系统，这些交换通过NVLink和NVSwitch以超快速度进行。这意味着你可以将训练作业或推理集群扩展到72个GPU，通信开销最小。而且由于GPU花费更少的时间等待彼此的数据，整体吞吐量几乎线性扩展到72个GPU。

> With an NVL72 system, those exchanges happen over NVLink and NVSwitch at a superfast pace. This means you can scale your training job or inference cluster up to 72 GPUs with minimal communication overhead. And since the GPUs spend far less time waiting for data from one another, overall throughput scales near-linearly up to 72 GPUs.

相比之下，考虑在类似规模的72 GPU H100集群（九个独立计算服务器，每个有八个Hopper H100 GPU）上扩展相同的作业。此配置需要InfiniBand，这将创建网络瓶颈，大大降低集群的扩展效率。

> In contrast, consider scaling the same job across a similarly sized 72-GPU H100 cluster of nine separate compute servers—each with eight Hopper H100 GPUs. This configuration requires InfiniBand, which will create network bottlenecks that greatly reduce the cluster's scaling efficiency.

让我们使用具体数字分析和比较NVL72和72 GPU H100集群。在单个NVL72机柜内，GPU到GPU带宽高达每GPU 1.8 TB/s（双向总和），延迟约为千字节级小消息的1-2微秒。大消息需要更长时间，通常受带宽限制。通过传统的InfiniBand网络，每GPU带宽可能更像20-80 GB/s——取决于有多少NIC及其速度——延迟可能为5-10微秒或更多。

> Let's analyze and compare the NVL72 and 72-GPU H100 clusters using concrete numbers. Within a single NVL72 rack, GPU-to-GPU bandwidth is up to 1.8 TB/s per GPU (bidirectional aggregate), and latency is on the order of 1–2 microseconds for a small message on the order of kilobytes. Large messages take longer and are typically bandwidth-limited. Across a conventional InfiniBand network, bandwidth per GPU might be more like 20–80 GB/s—depending on how many NICs and their speed—and latency is likely 5–10 microseconds or more.

NVL72网络提供比主机NIC架构更高的每GPU带宽和更低的延迟。具体来说，NVLink 5提供每GPU约1.8 TB/s的总带宽，而现代主机NIC在400-800 Gb/s线路速率下每端口提供约50-100 GB/s。所有这些将集合操作开销从百分之几十降低到仅几个百分点。

> The NVL72 network offers substantially higher per-GPU bandwidth and lower latency than host-NIC fabrics. Specifically, NVLink 5 provides about 1.8 TB/s of aggregate bandwidth per GPU, whereas modern host NICs provide about 50–100 GB/s per port at 400–800 Gb/s line rates. All of this decreases collective-operation overhead down from tens of percent down to just a few percent.

实际上，在NVLink连接的NVL72系统内，集合开销比传统节点到节点架构低得多，但迭代时间的确切比例取决于工作负载。例如，NVIDIA报告称，1.8万亿参数MoE模型从H100上每GPU约3.4个token每秒、第一个token时间超过5秒，改进到GB200 NVL72上每GPU约150个token每秒、第一个token时间约50毫秒。这种加速很大程度上是由于在NVL72机柜内消除了GPU间通信瓶颈，以及Blackwell更高的计算吞吐量。

> In practical terms, collective overhead is substantially lower within an NVLink-connected NVL72 system versus a traditional node-to-node fabric, but the exact fraction of iteration time is workload-dependent. For example, NVIDIA reported that a 1.8-trillion-parameter MoE model improved from about 3.4 tokens per second per GPU with over 5 seconds time to first token on H100 to about 150 tokens per second per GPU with roughly 50 ms time to first token on GB200 NVL72. This speedup is largely due to eliminating inter-GPU communication bottlenecks inside the NVL72 rack in addition to Blackwell's higher compute throughput.

在单个NVL72机柜内，通信如此之快，以至于通信瓶颈变得低优先级，因为它们几乎完全被消除，而传统InfiniBand和以太网集群中的通信通常是主要瓶颈，需要在软件级别进行仔细优化和调优。

> Within a single NVL72 rack, communication is so fast that communication bottlenecks become low priority as they are almost completely eliminated, whereas communication in traditional InfiniBand and Ethernet clusters is often the primary bottleneck and needs careful optimization and tuning at the software level.

简而言之，你应该设计和实现利用NVL72配置的软件，通过将尽可能多的工作负载通信保持在机柜内（"机柜内"）来利用高速NVLink和NVSwitch硬件。仅在绝对必要时使用机柜之间较慢的基于InfiniBand或以太网的通信（"机柜间"），以扩展超出NVL72的计算和内存资源。

> In short, you should design and implement software that exploits the NVL72 configuration by keeping as much of the workload's communication inside the rack ("intra-rack") as possible to take advantage of the high-speed NVLink and NVSwitch hardware. Use the slower InfiniBand- or Ethernet-based communication between racks ("inter-rack") only when absolutely necessary to scale beyond the NVL72's compute and memory resources.

### 2.6.3 使用NVIDIA SHARP的网络内聚合

另一个硬件启用的优化是NVIDIA可扩展分层聚合和归约协议（SHARP）。对于NVLink交换系统机柜，网络内归约使用集成到NVSwitch ASIC中的SHARP引擎在网络中卸载归约和其他集合操作（见图2-10）。

> Another hardware-enabled optimization is NVIDIA Scalable Hierarchical Aggregation and Reduction Protocol (SHARP). For NVLink Switch System racks, in-network reductions use SHARP engines integrated into NVSwitch ASICs to offload reductions and other collectives in-network (see Figure 2-10).

![图2-10 使用NVSwitch中的SHARP归约引擎将计算卸载到NVIDIA网络硬件](../assets/images/ch02/fig2_74_1.png)

NVSwitch架构组合部分结果，而无需数据通过GPU进行漏斗式传输。通过将集合计算从GPU卸载到交换机硬件本身，SHARP允许GPU专注于更复杂的计算，降低集合延迟，减少穿越网络的数据总量，并提高系统效率。

> The NVSwitch fabric combines partial results without the data needing to funnel through the GPUs. By offloading collective computations from the GPUs to the switch hardware itself, SHARP allows the GPUs to focus on more complex computations, lowers collective latencies, reduces the overall volume of data traversing the network, and increases system efficiency.

SHARP提高的效率意味着，在分布式训练期间，聚合梯度或同步参数的繁重工作由NVSwitch的专用SHARP引擎处理。结果是跨机柜内和机柜间配置的更高效扩展。使用SHARP，即使GPU数量增长，你也会看到接近线性的性能改进。这种网络内计算能力对于训练超大型模型尤为关键，其中在集合操作上节省的每一微秒都可以转化为显著的整体加速。

> SHARP's increased efficiency means that during distributed training, the heavy lifting of aggregating gradients or synchronizing parameters is handled by the NVSwitch's dedicated SHARP engines. The result is much more efficient scaling across both intra-rack and inter-rack configurations. With SHARP, you'll see near-linear performance improvements even as the number of GPUs grows. This in-network computing capability is especially critical for training ultralarge models, where every microsecond saved on collective operations can translate into substantial overall speedups.

SHARP是NVIDIA在2019-2020年收购Mellanox期间获得的最具影响力的创新之一。如果你目前没有使用SHARP，你应该探索它。SHARP可以显著减少集合操作的延迟和流量，通常可以提高通信受限训练的扩展效率。

> SHARP is one of the most impactful innovations that NVIDIA received during their 2019–2020 acquisition of Mellanox. You should explore SHARP if you are not currently using it. SHARP can significantly reduce latency and traffic for collectives and often improves scaling efficiency for communication-bound training.

## 2.7 计算密度和功率要求

NVL72机柜在计算方面密度极高，这意味着它对于单个机柜来说消耗非常高的功率。满载的NVL72在最大负载下可消耗高达约130 kW的功率。这比NVIDIA前一代AI机柜高出2倍多，后者消耗约50-60 kW。将72个尖端GPU——以及所有支持硬件——装入一个机柜，推动了数据中心基础设施能处理的极限。

> The NVL72 rack is incredibly dense in terms of compute, which means it draws a very high amount of power for a single rack. A fully loaded NVL72 can consume up to ~130 kW of power under max load. This is more than 2× NVIDIA's previous generation AI rack, which consumed around 50–60 kW. Packing 72 bleeding-edge GPUs—and all the supporting hardware—into one rack pushes the limits of what data center infrastructure can handle.

要为NVL72机柜提供130 kW，你不能只使用单个标准电源馈电。数据中心通常会配置多个高容量电路来提供这种功率。例如，数据中心可以部署两个完全独立的电源馈电。在这种情况下，每个馈电的大小都可以承载整个机柜负载，以防其中一个馈电发生故障。

> To supply 130 kW to the NVL72 rack, you can't just use a single standard power feed. Data centers will typically provision multiple high-capacity circuits to feed this kind of power. For instance, a data center can deploy two fully independent power feeds. In this case, each feed is sized to carry the entire rack load in case of a failure on one of the feeds.

如果一个馈电离线，剩余电路可以支持完整的130 kW负载，以避免电路跳闸。这种冗余是重要的保护。否则，电源中断可能会停止你长达数月的训练作业。

> If one feed goes offline, the remaining circuit can support the full 130 kW draw to avoid a blown circuit. This kind of redundancy is important protection. Otherwise, the power interruption could halt your multimonth training job.

在机柜内，功率分配到每个1U计算节点的电源。功率从AC转换为DC用于本地电子设备。NVL72中的每个计算节点包含两个Grace Blackwell超级芯片，它们共同消耗约6 kW的功率。有18个计算节点，总功耗约110 kW。NVSwitch托盘、网络交换机、空气冷却和水冷泵占总共约20 kW，整个NVL72机柜消耗130 kW。

> Within the rack, power is distributed to the power supplies of each 1U compute node. The power is converted from AC to DC for the local electronics. Each compute node in the NVL72 contains two Grace Blackwell Superchips, which together consume on the order of 6 kW. With 18 compute nodes, the total power consumed is ~110 kW. The NVSwitch trays, network switches, air cooling, and water cooling pumps account for ~20 kW for a total of 130 kW consumed by the entire NVL72 rack.

称这个处于高密度计算前沿的NVL72机柜为小型变电站并不夸张。八个这样的机柜组合成576个GPU将消耗近1 MW的功率（8机柜 × 130 kW每机柜），这是小型数据中心的整个容量！好的一面是，虽然130 kW在一个机柜中很多，但你也在每瓦上完成了很多工作。

> It's not far-fetched to call this NVL72 rack, at the cutting edge of high-density compute, a mini power substation. Eight of these racks combined for 576 GPUs would draw nearly 1 MW of power (8 racks × 130 kW per rack), which is the entire capacity of a small data center! The silver lining is that although 130 kW is a lot in one rack, you are also getting a lot of work done per watt.

## 2.8 液冷与风冷

在一个机柜中冷却130 kW超出了传统风冷的能力范围。对每个可散热约1,200瓦的72个GPU吹风将需要飓风般的气流，并且会非常嘈杂和低效——更不用说热空气排气将是残酷的。因此，液冷是在此功率密度下运行的NVL72机柜的唯一实用解决方案。

> Cooling 130 kW in one rack is beyond the reach of traditional air cooling. Blowing air over 72 GPUs that each can dissipate ~1,200 watts would require hurricane-like airflow and would be extremely loud and inefficient—not to mention the hot air exhaust would be brutal. As such, liquid cooling is the only practical solution for the NVL72 rack running at this power density.

NVL72是一个完全液冷的系统。每个Grace Blackwell超级芯片模块和每个NVSwitch芯片都附有冷板。冷板是带有内部管道的金属板，直接位于组件上。水基冷却液流过管道带走热量。所有这些冷板通过软管、歧管和泵连接，在整个系统中循环冷却液。

> The NVL72 is a fully liquid-cooled system. Each Grace Blackwell Superchip module and each NVSwitch chip has a cold plate attached. A cold plate is a metal plate with internal tubing that sits directly on the component. A water-based coolant liquid flows through the tubing to carry away heat. All these cold plates are linked by hoses, manifolds, and pumps that circulate the coolant throughout the system.

通常，机柜将为每个节点提供快速断开接头，以便你可以在不溢出冷却液的情况下滑入或滑出服务器。然后机柜有供应和返回连接到外部设施的冷水系统。通常，有一个称为冷却液分配单元（CDU）的热交换器，要么内置在机柜中，要么紧邻其旁边。CDU将热量从机柜的内部冷却液回路传递到数据中心的水回路。

> Typically, the rack will have quick-disconnect couplings for each node so you can slide a server in or out without spilling the coolant. The rack then has supply and return connections to the external facility's chilled water system. Often, there's a heat exchanger called a Coolant Distribution Unit (CDU) either built into the rack or immediately next to it. The CDU transfers heat from the rack's internal coolant loop to the data center's water loop.

设施提供20-30°C的冷水。水通过热交换器吸收热量。加热后的水然后被泵回冷却器或冷却塔再次冷却。在现代设计中，它们甚至可能运行温水冷却，其中冷水以30°C进入系统，以45°C离开。然后水可以通过蒸发冷却塔冷却，无需主动制冷，提高整体效率。关键是，水或液体冷却液每单位流量可以携带比空气更多的热量，因此液冷在小空间内高功率运行时效率大大提高。

> The facility provides chilled water at 20–30°C. The water absorbs the heat through the heat exchanger. The warmed-up water is then pumped back into the chillers or cooling towers to be cooled again. In modern designs, they might even run warm water cooling, in which chilled water comes into the system at 30°C and leaves at 45°C. The water can then be cooled by evaporative cooling towers without active refrigeration, improving overall efficiency. The point is, water, or a liquid coolant, can carry far more heat per unit of flow than air, so liquid cooling is vastly more effective when running at high watts in small spaces.

通过使GPU和CPU温度远低于风冷所能达到的温度，液冷减少了GPU热节流。GPU可以在不达到温度限制的情况下维持其最大时钟频率。此外，在较低温度下运行芯片提高了可靠性甚至效率，因为在较低温度下运行时功率泄漏较低。

> By keeping the GPU and CPU temperatures much lower than they would be with air, liquid cooling reduces thermal GPU throttling. The GPUs can sustain their maximum clocks without hitting temperature limits. Also, running chips cooler improves reliability and even efficiency since power leakage is lower when running at lower temperatures.

NVL72将GPU温度保持在负载下的50-70°C范围内，这对于如此耗电的设备来说是极好的。冷板和冷却液回路经过非常仔细的工程设计，允许每个GPU向系统排放1,000 W，每个CPU排放500 W。此外，冷却液流量必须足够以快速移除该热量。粗略估计显示，在10-12°C水温上升的情况下，需要约150-200升每分钟的流量来散热约130 kW。

> The NVL72 keeps GPU temps in the 50–70°C range under load, which is excellent for such power-hungry devices. The cold plates and coolant loops have been engineered very carefully to allow each GPU to dump 1,000 W and each CPU to dump 500 W into the system. In addition, the coolant flow rate has to be sufficient to remove that heat quickly. A rough estimate shows on the order of 150–200 liters per minute at a 10–12°C water temperature rise to dissipate about 130 kW.

这种级别的机柜液冷曾经是罕见的，但现在已成为这些大规模AI集群的标准。Meta、xAI和Google等公司正在为其AI集群采用液冷，因为风冷根本无法支持从这些系统汲取的大量功率。

> This level of liquid cooling in racks was once exotic, but it is now the standard for these large-scale AI clusters. Companies like Meta, xAI, and Google are adopting liquid cooling for their AI clusters because air cooling simply cannot support the large amount of power drawn from these systems.

## 2.9 展望未来：NVIDIA的路线图

在撰写本文时，Grace Blackwell NVL72平台代表了AI硬件的最先进水平。但NVIDIA已经在准备下一个飞跃。值得简要了解NVIDIA未来几年的硬件路线图，因为它显示了清晰的扩展模式。NVIDIA打算继续在性能、内存和集成方面加倍投入。

> At the time of writing, the Grace Blackwell NVL72 platform represents the state-of-the-art in AI hardware. But NVIDIA is already preparing the next leaps. It's worth briefly looking at NVIDIA's hardware roadmap for the coming few years, because it shows a clear pattern of scaling. NVIDIA intends to continue doubling down on performance, memory, and integration.

### 2.9.1 Blackwell Ultra和Grace Blackwell Ultra

NVIDIA的Blackwell Ultra（B300）和相应的Grace Blackwell Ultra超级芯片（GB300）是NVL72架构的直接升级。每个Blackwell Ultra B300 GPU比B200（180 GB）具有约50%更高的内存容量（288 GB）——以及1.5倍更高的AI计算性能和更大的片上加速器，专门为注意力操作和降低精度（如NVFP4）设计。这意味着Blackwell B300比B200产生45-50%更高的推理吞吐量。

> NVIDIA's Blackwell Ultra (B300) and corresponding Grace Blackwell Ultra Superchip (GB300) are a drop-in upgrade to the NVL72 architecture. Each Blackwell Ultra B300 GPU has approximately 50% more memory capacity (288 GB) than the B200 (180 GB)—as well as 1.5× higher AI compute performance and larger on-die accelerators specifically designed for attention operations and reduced precision (e.g., NVFP4). This translates to the Blackwell B300 producing 45-50% higher inference throughput than the B200.

### 2.9.2 Vera Rubin超级芯片（2026）

以女性天文学家命名的Vera Rubin超级芯片（VR200）是下一个主要架构步骤。Vera是Grace CPU的基于ARM的CPU继任者，Rubin是Blackwell的GPU架构继任者。NVIDIA继续超级芯片概念，将一个Vera CPU与两个Rubin GPU组合在单个模块（VR200）中，类似于Grace Blackwell（GB200/GB300）配置。

> Codenamed after the female astronomer whose work provided evidence of dark matter, the Vera Rubin Superchip (VR200) is the next major architecture step. Vera is the ARM-based CPU successor to the Grace CPU, and Rubin is the GPU architecture successor to Blackwell. NVIDIA continues the superchip concept by combining one Vera CPU with two Rubin GPUs in a single module (VR200) similar to the Grace Blackwell (GB200/GB300) configuration.

Vera CPU使用TSMC的3nm半导体工艺，具有更多CPU核心和以约1 TB/s运行的更快LPDDR6内存。Rubin GPU支持以约13-14 TB/s运行的更高GPU高带宽内存（HBM）。

> The Vera CPU uses TSMC's 3nm semiconductor process with more CPU cores and faster LPDDR6 memory running at approximately 1 TB/s. The Rubin GPU supports higher GPU high-bandwidth memory (HBM) running at approximately 13–14 TB/s.

NVLink也有望移动到第六代NVLink 6，这将使CPU到GPU和GPU到GPU的链路带宽翻倍。底线是Vera Rubin代在大多数指标上又是约2倍的跳跃，包括更多核心、更多内存、更多带宽和更多TFLOPS。

> NVLink is also expected to move to its sixth generation, NVLink 6, which would double the CPU-to-GPU and GPU-to-GPU link bandwidth. The bottom line is that the Vera Rubin generation is yet another ~2× jump in most metrics, including more cores, more memory, more bandwidth, and more TFLOPS.

### 2.9.3 Feynman GPU（2028）

NVIDIA将后Rubin代命名为Feynman，计划于2028年发布。细节很少，但Feynman GPU可能会移动到更精细的2 nm TSMC工艺节点。它可能会使用HBM5并在模块内包含更多DDR内存。也许它会将裸片数量从四个翻倍到八个。

> NVIDIA has code-named the post-Rubin generation as Feynman, which is scheduled for a 2028 release. Details are scarce, but the Feynman GPU will likely move to an even finer 2 nm TSMC process node. It will likely use HBM5 and include even more DDR memory inside the module. And perhaps it will double the number of dies from four to eight.

NVIDIA似乎每年都在翻倍某些东西。一年他们翻倍内存，另一年翻倍裸片数量，再一年翻倍互连带宽，等等。几年下来，这种翻倍的复合效应是巨大的。

> NVIDIA seems to be doubling something every generation, every year if possible. One year they double memory, another year they double the number of dies, another year they double interconnect bandwidth, and so on. Over a few years, the compound effect of this doubling is huge.

## 2.10 关键要点

以下创新共同使NVIDIA的硬件能够以前所未有的速度、效率和可扩展性处理超大型AI模型：

> The following innovations collectively enable NVIDIA's hardware to handle ultralarge AI models with unprecedented speed, efficiency, and scalability:

**集成超级芯片架构**：NVIDIA将基于ARM的CPU（Grace）与GPU（Hopper/Blackwell）融合到单个超级芯片中，创建了统一内存空间。这种设计通过消除CPU和GPU之间手动数据传输的需要，简化了数据管理。

> **Integrated superchip architecture**: NVIDIA fuses ARM-based CPUs (Grace) with GPUs (Hopper/Blackwell) into a single superchip, which creates a unified memory space. This design simplifies data management by eliminating the need for manual data transfers between CPU and GPU.

**统一内存架构**：统一内存架构和一致互连降低了编程复杂性。开发人员可以编写代码而无需担心显式数据移动，这加速了开发并帮助他们专注于改进AI算法。

> **Unified memory architecture**: The unified memory architecture and coherent interconnect reduce the programming complexity. Developers can write code without worrying about explicit data movement, which accelerates development and helps them focus on improving AI algorithms.

**超快互连**：使用NVLink（包括NVLink-C2C和NVLink 5）和NVSwitch，系统实现了极高的机柜内带宽和低延迟。这意味着GPU几乎可以像大型处理器的一部分一样进行通信，这对于扩展AI训练和推理至关重要。

> **Ultrafast interconnects**: Using NVLink (including NVLink-C2C and NVLink 5) and NVSwitch, the system achieves extremely high intra-rack bandwidth and low latency. This means GPUs can communicate nearly as if they were parts of one large processor, which is critical for scaling AI training and inference.

**高密度、超大规模系统（NVL72）**：NVL72机柜在一个紧凑的系统中集成了72个GPU。这种整合设计通过将高计算性能与巨大的统一内存池相结合，支持大规模模型，使传统设置上不切实际的任务成为可能。

> **High-density, ultrascale system (NVL72)**: The NVL72 rack integrates 72 GPUs in one compact system. This consolidated design supports massive models by combining high compute performance with an enormous unified memory pool, enabling tasks that would be impractical on traditional setups.

**先进冷却和功率管理**：NVL72依赖复杂的液冷和强大的配电系统，每个机柜以约130 kW运行。这种冷却和功率量对于管理高密度、高性能组件和确保可靠运行至关重要。

> **Advanced cooling and power management**: NVL72 relies on sophisticated liquid cooling and robust power distribution systems and operates at around 130 kW per rack. This amount of cooling and power are essential for managing the high-density, high-performance components and ensuring reliable operation.

**显著的性能和效率提升**：与前几代（如Hopper H100）相比，Blackwell GPU在计算和内存带宽方面提供约2-2.5倍的改进。这导致训练和推理速度的显著提升——在使用Blackwell的FP4 Tensor Core和Transformer Engine的某些情况下，推理速度提高30倍——以及通过减少GPU数量实现的潜在成本节约。

> **Significant performance and efficiency gains**: Compared to previous generations such as the Hopper H100, Blackwell GPUs offer roughly 2–2.5× improvements in compute and memory bandwidth. This leads to significant improvements in training and inference speeds—up to 30× faster inference in some cases that use Blackwell's FP4 Tensor Cores and Transformer Engine—as well as potential cost savings through reduced GPU counts.

**面向未来的路线图**：NVIDIA的开发路线图（包括Blackwell Ultra、Vera Rubin、Vera Rubin Ultra和Feynman）承诺持续翻倍计算吞吐量和内存带宽等关键参数。这一轨迹旨在支持未来更大型的AI模型和更复杂的工作负载。

> **Future-proof roadmap**: NVIDIA's development roadmap (including Blackwell Ultra, Vera Rubin, Vera Rubin Ultra, and Feynman) promises continual doubling of key parameters like compute throughput and memory bandwidth. This trajectory is designed to support ever-larger AI models and more complex workloads in the future.

## 2.11 结论

NVIDIA NVL72系统——及其Grace Blackwell超级芯片、NVLink架构和先进冷却——体现了AI硬件设计的最前沿。在本章中，我们看到了每个组件如何协同设计以服务于加速AI工作负载的单一目标。CPU和GPU融合为一个单元，以消除数据传输瓶颈并提供巨大的统一内存。

> The NVIDIA NVL72 system—with its Grace Blackwell Superchips, NVLink fabric, and advanced cooling—exemplifies the cutting-edge of AI hardware design. In this chapter, we've seen how every component is codesigned to serve the singular goal of accelerating AI workloads. The CPU and GPU are fused into one unit to eliminate data transfer bottlenecks and provide a gigantic, unified memory.

数十个GPU通过超快网络连接在一起，使它们表现得像一个巨大的GPU，通信延迟最小。内存子系统被扩展和加速，以满足GPU核心的贪婪需求。甚至功率输送和热管理也被推向新高度，以允许这种计算密度。

> Dozens of GPUs are wired together with an ultrafast network so they behave like one colossal GPU with minimal communication delay. And the memory subsystem is expanded and accelerated to feed the voracious appetite of the GPU cores. Even the power delivery and thermal management are pushed to new heights to allow this density of computing.

结果是一个单一机柜提供了以前只有在多机柜超级计算机中才能看到的性能。NVIDIA采用了整个计算栈——芯片、板、网络、冷却——并端到端优化，以允许在超大规模下训练和服务大规模AI模型。

> The result is a single rack that delivers performance previously seen only in multirack supercomputers. NVIDIA took the entire computing stack—chips, boards, networking, cooling—and optimized it end to end to allow training and serving massive AI models at ultrascale.

但这种硬件创新带来了挑战，因为你需要专门的设施、仔细的功率和冷却规划，以及复杂的软件来充分利用它们。但回报是巨大的。研究人员现在可以以前所未有的规模和复杂性进行模型实验，而无需等待数周或数月的结果。在旧基础设施上可能需要一个月训练的模型可能在NVL72上几天内完成训练。几乎不具交互性的推理任务（每查询数秒）现在成为实时（毫秒）现实。这为以前不切实际的AI应用打开了大门，例如万亿参数交互式AI助手和智能体。

> But such hardware innovations come with challenges, as you need specialized facilities, careful planning for power and cooling, and sophisticated software to utilize them fully. But the payoff is immense. Researchers can now experiment with models of unprecedented scale and complexity without waiting weeks or months for results. A model that might have taken a month to train on older infrastructure might train in a few days on NVL72. Inference tasks that were barely interactive (seconds per query) are now a real-time (milliseconds) reality. This opens the door for AI applications that were previously impractical, such as multi-trillion-parameter interactive AI assistants and agents.

NVIDIA的快速路线图表明这仅仅是开始。Grace Blackwell架构将演变为Vera Rubin和Feynman及更高版本。正如NVIDIA首席执行官Jensen Huang所描述的："AI正以光速前进，公司正在竞相建设AI工厂，以扩展满足推理AI和推理时间扩展的处理需求。"

> NVIDIA's rapid roadmap suggests that this is just the beginning. The Grace Blackwell architecture will evolve into Vera Rubin and Feynman and beyond. As NVIDIA's CEO, Jensen Huang, describes, "AI is advancing at light speed, and companies are racing to build AI factories that can scale to meet the processing demands of reasoning AI and inference time scaling."

NVL72及其继任者是AI工厂的核心。它是将通过大量数据产生惊人AI能力的重要机械。作为性能工程师，我们站在这一硬件创新的肩膀上。它为我们提供了巨大的原始能力，我们的角色是通过开发充分利用硬件潜力的软件和算法来利用这一创新。

> The NVL72 and its successors are the core of the AI factory. It's the heavy machinery that will churn through mountains of data to produce incredible AI capabilities. As performance engineers, we stand on the shoulders of this hardware innovation. It gives us a tremendous raw capability, as our role is to harness this innovation by developing software and algorithms that make the most of the hardware's potential.

在下一章中，我们将从硬件转向软件。我们将探讨如何优化NVL72等系统上的操作系统、驱动程序和库，以确保这些令人敬畏的硬件不会被充分利用不足。在后面的章节中，我们将研究补充软件架构的内存管理和分布式训练/推理算法。

> In the next chapter, we will transition from hardware to software. We'll explore how to optimize the operating systems, drivers, and libraries on systems like NVL72 to ensure that none of this awesome hardware goes underutilized. In later chapters, we'll look at memory management and distributed training/inference algorithms that complement the software architecture.

本书的主题是协同设计。正如硬件是为AI协同设计的，我们的软件和方法必须协同设计以利用硬件。现在对硬件基础有了清晰的了解，我们准备好深入研究改进AI系统性能的软件策略。AI超级计算时代已经到来，充分利用它将是一段激动人心的旅程。

> The theme for this book is codesign. Just as the hardware was codesigned for AI, our software and methods must be codesigned to leverage the hardware. With a clear understanding of the hardware fundamentals now, we're equipped to dive into software strategies to improve AI system performance. The era of AI supercomputing is here, and it's going to be a thrilling ride utilizing it to its fullest.
