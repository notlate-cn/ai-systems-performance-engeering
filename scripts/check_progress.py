#!/usr/bin/env python3
"""
ç¿»è¯‘è¿›åº¦æ£€æŸ¥å·¥å…·
æ£€æŸ¥å„ç« èŠ‚çš„ç¿»è¯‘çŠ¶æ€
"""

import os
import re
from pathlib import Path

DOCS_DIR = Path(__file__).parent.parent / "docs" / "chapters"

CHAPTERS = {
    "ch01": "Introduction and AI System Overview",
    "ch02": "AI System Hardware Overview",
    "ch03": "OS, Docker, and Kubernetes Tuning for GPU-Based Environments",
    "ch04": "Tuning Distributed Networking Communication",
    "ch05": "GPU-Based Storage I/O Optimizations",
    "ch06": "GPU Architecture, CUDA Programming, and Maximizing Occupancy",
    "ch07": "Profiling and Tuning GPU Memory Access Patterns",
    "ch08": "Occupancy Tuning, Warp Efficiency, and Instruction-Level Parallelism",
    "ch09": "Increasing CUDA Kernel Efficiency and Arithmetic Intensity",
    "ch10": "Intra-Kernel Pipelining, Warp Specialization, and Cooperative Thread Block Clusters",
    "ch11": "Inter-Kernel Pipelining, Synchronization, and CUDA Stream-Ordered Memory Allocations",
    "ch12": "Dynamic Scheduling, CUDA Graphs, and Device-Initiated Kernel Orchestration",
    "ch13": "Profiling, Tuning, and Scaling PyTorch",
    "ch14": "PyTorch Compiler, OpenAI Triton, and XLA Backends",
    "ch15": "Multinode Inference, Parallelism, Decoding, and Routing Optimizations",
    "ch16": "Profiling, Debugging, and Tuning Inference at Scale",
    "ch17": "Scaling Disaggregated Prefill and Decode for Inference",
    "ch18": "Advanced Prefill-Decode and KV Cache Tuning",
    "ch19": "Dynamic and Adaptive Inference Engine Optimizations",
    "ch20": "AI-Assisted Performance Optimizations and Scaling Toward Multimillion GPU Clusters",
}

def check_chapter_status(file_path: Path) -> dict:
    """æ£€æŸ¥ç« èŠ‚ç¿»è¯‘çŠ¶æ€"""
    if not file_path.exists():
        return {"exists": False, "lines": 0, "has_content": False, "progress": "âŒ æœªåˆ›å»º"}
    
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    lines = len(content.strip().split("\n"))
    has_placeholder = "ğŸš§" in content or "ç¿»è¯‘è¿›è¡Œä¸­" in content
    
    if has_placeholder and lines < 20:
        progress = "â³ å¾…ç¿»è¯‘"
    elif lines > 100:
        progress = "âœ… å·²å®Œæˆ"
    elif lines > 50:
        progress = "ğŸ”„ è¿›è¡Œä¸­"
    else:
        progress = "â³ å¾…ç¿»è¯‘"
    
    return {
        "exists": True,
        "lines": lines,
        "has_content": lines > 10 and not has_placeholder,
        "progress": progress
    }

def main():
    print("=" * 60)
    print("ğŸ“š AI Systems Performance Engineering ç¿»è¯‘è¿›åº¦")
    print("=" * 60)
    print()
    
    total = len(CHAPTERS)
    completed = 0
    in_progress = 0
    pending = 0
    
    for ch_id, ch_title in CHAPTERS.items():
        file_path = DOCS_DIR / f"{ch_id}.md"
        status = check_chapter_status(file_path)
        
        if "âœ…" in status["progress"]:
            completed += 1
        elif "ğŸ”„" in status["progress"]:
            in_progress += 1
        else:
            pending += 1
        
        lines_info = f"({status['lines']} è¡Œ)" if status["exists"] else ""
        print(f"  {ch_id}: {status['progress']} {ch_title} {lines_info}")
    
    print()
    print("-" * 60)
    print(f"  ğŸ“Š ç»Ÿè®¡: âœ… å·²å®Œæˆ {completed} | ğŸ”„ è¿›è¡Œä¸­ {in_progress} | â³ å¾…ç¿»è¯‘ {pending}")
    print(f"  ğŸ“ˆ æ€»è¿›åº¦: {completed}/{total} ({completed/total*100:.1f}%)")
    print("=" * 60)

if __name__ == "__main__":
    main()
